{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "import keras\n",
    "from keras.layers import Conv2D, Conv2DTranspose, Input, UpSampling2D\n",
    "from keras.models import Sequential\n",
    "\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a 4-D array to represent the input. The 4-day array is structured as ( image number, height, width, num of channels ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 5, 5, 1)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.diag((5,5,5,5,5)).reshape((5,5,1))\n",
    "b = np.diag((1,1,1,1,1)).reshape((5,5,1))\n",
    "x = np.array([a,b])\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backend function to retreive the output of first layer\n",
    "def get_layer_output(x,model,layer=0):\n",
    "    \n",
    "    layer_output = K.function([model.layers[layer].input],[model.layers[layer].output])\n",
    "    return layer_output([x])\n",
    "\n",
    "# Backend function to retreive the kernel weights of the first layer\n",
    "def get_kernel_output(x,model,layer=0):\n",
    "    \n",
    "    kernel_output = K.function([model.layers[layer].input],[model.layers[layer].kernel])\n",
    "    return kernel_output([x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiplySum(x,y):\n",
    "    \n",
    "    out = []\n",
    "    \n",
    "    val = 0.0\n",
    "    \n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            val += x[i][j]*y[i][j]\n",
    "            \n",
    "    return val\n",
    "\n",
    "def getKernel(x,channel=0, kernel=0):\n",
    "    return(x[0][:,:,channel, kernel])\n",
    "    \n",
    "def getOutput(x, kernel=0, inputImage = 0):\n",
    "    return(x[0][inputImage, : , : , kernel])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolve(x, kernel, stride = (1,1),padding=None):\n",
    "    \n",
    "    \n",
    "    if padding!=None:\n",
    "        temp = np.zeros((x.shape[0]+2*padding[0] , x.shape[1]+2*padding[1]))\n",
    "        temp[padding[0]:(padding[0]+x.shape[0]) , padding[1]:(padding[1]+x.shape[1])] = x\n",
    "        x = temp\n",
    "        print(x)\n",
    "    \n",
    "    \n",
    "    kernel_size = kernel.shape[0]\n",
    "    \n",
    "    out_size = ((x.shape[0]  - kernel_size)/stride[0] + 1 , (x.shape[1]  - kernel_size)/stride[1] + 1)\n",
    "    \n",
    "    output = np.zeros(out_size)\n",
    "    \n",
    "    for i in range(0,out_size[0]):\n",
    "        for j in range(0,out_size[1]):\n",
    "            \n",
    "            output[i][j] = multiplySum(x[i*stride[0]:(i*stride[0]+kernel_size) , j*stride[1]:(j*stride[1]+kernel_size)] , kernel )\n",
    "            \n",
    "    return np.array(output)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conv2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_22 (Conv2D)           (None, 3, 3, 2)           20        \n",
      "=================================================================\n",
      "Total params: 20\n",
      "Trainable params: 20\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(2,(3,3), input_shape=(5,5,1)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3, 3, 2)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "The output is a 4-d array where the structure of the array is ( image number, height, width, kernel )\n",
    "So output[0,:,:,:] represents the outputs of the convolution of the kernels on the first image\n",
    "Similarly, output[:,:,:,1] represent the outputs of the convolution of the images with the second kernel\n",
    "\n",
    "\"\"\"\n",
    "output = layer_output([x])\n",
    "output[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3, 1, 2)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "The output of kernel_output is a 4-D array where the structure is ( height, width, channel, kernel number)\n",
    "\n",
    "weight[:,:,:,0] represents the first kernel for the first channel.\n",
    "\n",
    "If the input image had 3 channels, then weight shape will be (3,3,3,2). Therefore, even if we define only 1 kernel, \n",
    "if there n channels in the image, then n 3x3 matrices are created to represent the kernel. \n",
    "\n",
    "In other words, each kernel has different weight matrices for different input channel\n",
    "\"\"\"\n",
    "\n",
    "weight = kernel_output([x])\n",
    "weight[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_final = x[0,:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.15143082,  2.094208  ,  1.01403967],\n",
       "       [-2.0393534 , -0.15143082,  2.094208  ],\n",
       "       [ 0.16954944, -2.0393534 , -0.15143082]])"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convolve(x_final,getKernel(weight, kernel=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.15143076,  2.094208  ,  1.0140396 ],\n",
       "       [-2.0393534 , -0.15143037,  2.094208  ],\n",
       "       [ 0.16954947, -2.0393534 , -0.15143076]], dtype=float32)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getOutput(output, kernel=0,inputImage=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution with strides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_24 (Conv2D)           (None, 2, 2, 2)           20        \n",
      "=================================================================\n",
      "Total params: 20\n",
      "Trainable params: 20\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(2,(3,3), strides=(2,2), input_shape=(5,5,1)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2, 2, 2)"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = get_layer_output(x,model)\n",
    "output[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3, 1, 2)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight = get_kernel_output(x,model)\n",
    "weight[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.61574216, 0.        ],\n",
       "       [0.        , 0.        ]])"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convolve(x_final,getKernel(weight, kernel=0), stride=(2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 0, 0, 0, 0],\n",
       "       [0, 5, 0, 0, 0],\n",
       "       [0, 0, 5, 0, 0],\n",
       "       [0, 0, 0, 5, 0],\n",
       "       [0, 0, 0, 0, 5]])"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.37873605, -0.21734086,  0.10111681],\n",
       "       [ 0.39398727,  0.38138524, -0.14542866],\n",
       "       [-0.13162675,  0.29388335, -0.23697285]], dtype=float32)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getKernel(weight,kernel=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.61574216, -0.65813377],\n",
       "       [ 0.50558403,  2.61574216]])"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convolve(x_final,getKernel(weight, kernel=0), stride=(2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.6157422 , -0.65813375],\n",
       "       [ 0.505584  ,  2.6157422 ]], dtype=float32)"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getOutput(output,inputImage=0,kernel=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.34536022,  1.31472543],\n",
       "       [ 1.07642606, -2.34536022]])"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convolve(x_final,getKernel(weight, kernel=1), stride=(2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.3453603,  1.3147254],\n",
       "       [ 1.076426 , -2.3453603]], dtype=float32)"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getOutput(output,inputImage=0,kernel=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upsampling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "up_sampling2d_1 (UpSampling2 (None, 10, 10, 1)         0         \n",
      "=================================================================\n",
      "Total params: 0\n",
      "Trainable params: 0\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(UpSampling2D((2,2), input_shape=(5,5,1)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = get_layer_output(x,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5., 5., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [5., 5., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 5., 5., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 5., 5., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 5., 5., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 5., 5., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 5., 5., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 5., 5., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 5., 5.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 5., 5.]], dtype=float32)"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Imagine every single cell in your input array being replaced by a new cell of size (2,2) { (2,2) because thats \n",
    "parameter that we have passed to UpSampling2D}.\n",
    "\"\"\"\n",
    "getOutput(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.array([[1,2,3],[4,5,6]]).reshape(1,2,3,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "up_sampling2d_3 (UpSampling2 (None, 6, 3, 1)           0         \n",
      "=================================================================\n",
      "Total params: 0\n",
      "Trainable params: 0\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 3.],\n",
       "       [1., 2., 3.],\n",
       "       [1., 2., 3.],\n",
       "       [4., 5., 6.],\n",
       "       [4., 5., 6.],\n",
       "       [4., 5., 6.]], dtype=float32)"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(UpSampling2D((3,1), input_shape=(2,3,1)))\n",
    "model.summary()\n",
    "output = get_layer_output(x1,model)\n",
    "getOutput(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[1],\n",
       "         [0],\n",
       "         [0]],\n",
       "\n",
       "        [[0],\n",
       "         [1],\n",
       "         [0]],\n",
       "\n",
       "        [[0],\n",
       "         [0],\n",
       "         [1]]]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # def upsampleMatrix():\n",
    "\n",
    "# y = np.diag([1,1,1])\n",
    "# y = y.reshape(1,y.shape[0],y.shape[1],1)\n",
    "# y\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(UpSampling2D((factor,factor), input_shape=(y.shape[1],y.shape[2], y.shape[3])))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conv2DTranspose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stride 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### same padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.diag((1,1,1)).reshape(1,3,3,1)\n",
    "x_final=x[0,:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_transpose_10 (Conv2DT (None, 3, 3, 1)           10        \n",
      "=================================================================\n",
      "Total params: 10\n",
      "Trainable params: 10\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2DTranspose(1,(3,3), strides=(1,1),padding='same', input_shape=(3,3,1)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.23676872,  0.23019093, -0.04622787],\n",
       "       [-0.4418265 ,  0.11311585, -0.38515693],\n",
       "       [ 0.36979067,  0.2140702 , -0.41140068]], dtype=float32)"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight = get_kernel_output(x,model)\n",
    "getKernel(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.34988457, -0.154966  , -0.04622787],\n",
       "       [-0.22775626, -0.06151611, -0.154966  ],\n",
       "       [ 0.36979067, -0.22775626, -0.29828483]], dtype=float32)"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = get_layer_output(x,model)\n",
    "getOutput(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.29828483, -0.154966  , -0.04622787],\n",
       "       [-0.22775629, -0.06151611, -0.154966  ],\n",
       "       [ 0.36979067, -0.22775629,  0.34988457]])"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convolve(x_final,getKernel(weight, kernel=0).T, stride=(1,1),padding=(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.34988457, -0.154966  , -0.04622787],\n",
       "       [-0.22775626, -0.06151611, -0.154966  ],\n",
       "       [ 0.36979067, -0.22775626, -0.29828483]], dtype=float32)"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getOutput(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### valid padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_transpose_1 (Conv2DTr (None, 5, 5, 1)           10        \n",
      "=================================================================\n",
      "Total params: 10\n",
      "Trainable params: 10\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2DTranspose(1,(3,3), strides=(1,1),padding='valid', input_shape=(3,3,1)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00166929, -0.4668319 , -0.45973036],\n",
       "       [ 0.38341302,  0.49846447, -0.33313805],\n",
       "       [ 0.39259535,  0.44750214, -0.43990558]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight = get_kernel_output(x,model)\n",
    "getKernel(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00166929, -0.46683192, -0.4597304 ,  0.        ,  0.        ],\n",
       "       [ 0.38341302,  0.50013375, -0.79997   , -0.45973036,  0.        ],\n",
       "       [ 0.39259535,  0.83091515,  0.06022817, -0.79997   , -0.4597304 ],\n",
       "       [ 0.        ,  0.39259535,  0.83091515,  0.05855885, -0.33313805],\n",
       "       [ 0.        ,  0.        ,  0.39259535,  0.44750214, -0.43990558]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = get_layer_output(x,model)\n",
    "getOutput(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deconvolve(x,kernel,stride = 1):\n",
    "    \n",
    "    out_size = x.shape[0]*stride + max( (kernel.shape[0]-stride) , 0 )\n",
    "    \n",
    "    output = np.zeros((out_size,out_size))\n",
    "    \n",
    "    \n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            \n",
    "            val = kernel*x[i][j]\n",
    "            \n",
    "            output[i*stride:(i*stride+kernel.shape[0]) , j*stride:(j*stride+kernel.shape[0])] += val\n",
    "            \n",
    "    return output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00166929, -0.46683189, -0.45973036,  0.        ,  0.        ],\n",
       "       [ 0.38341302,  0.50013375, -0.79996994, -0.45973036,  0.        ],\n",
       "       [ 0.39259535,  0.83091515,  0.06022817, -0.79996994, -0.45973036],\n",
       "       [ 0.        ,  0.39259535,  0.83091515,  0.05855888, -0.33313805],\n",
       "       [ 0.        ,  0.        ,  0.39259535,  0.44750214, -0.43990558]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deconvolve(x_final,getKernel(weight, kernel=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.05855888,  0.83091515,  0.39259535],\n",
       "       [-0.79996994,  0.06022817,  0.83091515],\n",
       "       [-0.45973036, -0.79996994,  0.50013375]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Comparing the output of convolve with padding (1,1) with the output of deconvolve, we can see that the \n",
    "central 3x3 region of the 5x5 output of deconvolve corresponds to the output of convolve. Therefore, to go from \n",
    "\"valid\" padding to \"same\", we can just crop down the edges of the output of \"valid\" padding\n",
    "\"\"\"\n",
    "convolve(x_final,getKernel(weight, kernel=0), stride=(1,1),padding=(1,1))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Suppose input 3x3 matrix X is represented as [x0,x1,x2...x8] and 3x3 kernel W is represented as [w0,w1,w2,w3...w8].\n",
    "Then for a simple case of transpose 2D Convolution with stride 1, the operation can be considered to be similar\n",
    "to the convolution operator itself (Provided we use the \"same\" padding, that removes the extra rows and columns\n",
    "from the output of Conv2DTranspose). \n",
    "\n",
    "However there is a small difference in the results in the order of the kernel thats applied\n",
    "\n",
    "Let O be the 5x5 matrix output of transpose convolution on X using the kernel W, represented by [o0,o1,o2...o24]\n",
    "\n",
    "From computations,\n",
    "o6 = x0*w4 + x1*w3 + x3*w1 + x4*w0\n",
    "o7 = x0*w5 + x1*w4 + x2*w3 + x3*w2 + x4*w1 + x5*w0\n",
    "\n",
    "It can be easier to imagine the convolution operator working on X if we assume it to be padded by a layer of 0's\n",
    "\n",
    "0  0  0  0  0\n",
    "0  x0 x1 x2 0\n",
    "0  x3 x4 x5 0\n",
    "0  x6 x7 x8 0\n",
    "0  0  0  0  0\n",
    "\n",
    "Keep in mind that padding with 0s followed by convolution with the kernel gives the Conv2DTranspose output when \n",
    "\"same\" padding is used ( an output of 3x3) and not when a \"valid\" padding is used (an output of 5x5). But the \n",
    "important thing to keep in mind is that the output of \"same\" padding and the central 3x3 region of the \n",
    "output of \"valid\" padding are the same. Therefore, the values that we are comparing are the same.\n",
    "\n",
    "So the small difference in the results( between using Conv2D and Conv2DTranspose) occurs due to \n",
    "the order in which the kernel is applied. \n",
    "If you notice the computation of o6, The normal convolution operation would have been computed as :\n",
    "o6 = 0*w0 + 0*w1 + 0*w2 + 0*w3 + (x0*w4 + x1*w5 + x3*w7 + x4*w8) + 0*w6\n",
    "Instead, the actual computation that happens is :\n",
    "o6 = x0*w4 + x1*w3 + x3*w1 + x4*w0\n",
    "\n",
    "This output can be generated using Conv2D, when the kernel is flipped by its rows and then its columns(or vice versa)\n",
    "\n",
    "This is shown in the next step, when the weight kernel is flipped by its rows and columns and then fed into \n",
    "the convolution operator and the values are now aligned with the output of Conv2DTranspose\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.50013375, -0.79996994, -0.45973036],\n",
       "       [ 0.83091515,  0.06022817, -0.79996994],\n",
       "       [ 0.39259535,  0.83091515,  0.05855888]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convolve(x_final,np.flip(np.flip(getKernel(weight, kernel=0),0),1), stride=(1,1),padding=(1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stride 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### valid padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_transpose_2 (Conv2DTr (None, 7, 7, 1)           10        \n",
      "=================================================================\n",
      "Total params: 10\n",
      "Trainable params: 10\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2DTranspose(1,(3,3), strides=(2,2),padding='valid', input_shape=(3,3,1)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.42253345,  0.34132046, -0.32057053],\n",
       "       [-0.3672353 , -0.2650267 ,  0.30951786],\n",
       "       [ 0.26088667, -0.5487001 ,  0.49119878]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight = get_kernel_output(x,model)\n",
    "getKernel(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.42253345,  0.34132046, -0.32057053,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.3672353 , -0.2650267 ,  0.30951786,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.26088667, -0.5487001 ,  0.06866533,  0.34132046, -0.32057053,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        , -0.3672353 , -0.2650267 ,  0.30951786,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.26088667, -0.5487001 ,  0.06866533,\n",
       "         0.34132046, -0.32057053],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        , -0.3672353 ,\n",
       "        -0.2650267 ,  0.30951786],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.26088667,\n",
       "        -0.5487001 ,  0.49119878]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = get_layer_output(x,model)\n",
    "getOutput(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.423,  0.341, -0.321,  0.   ,  0.   ,  0.   ,  0.   ],\n",
       "       [-0.367, -0.265,  0.31 ,  0.   ,  0.   ,  0.   ,  0.   ],\n",
       "       [ 0.261, -0.549,  0.069,  0.341, -0.321,  0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   , -0.367, -0.265,  0.31 ,  0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ,  0.261, -0.549,  0.069,  0.341, -0.321],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   , -0.367, -0.265,  0.31 ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.   ,  0.261, -0.549,  0.491]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.matrix.round(deconvolve(x_final,getKernel(weight, kernel=0),stride=2),3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for equivalance between Conv2DTranpose and ( Upsampling + Conv2D)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Here there is a difference in the upsampling that we do. In the conventional upsampling, when a single cell \n",
    "is expanded to its new size, the value of the cell is duplicated in all the new cells of the expanded cell block.\n",
    "\n",
    "1 2\n",
    "3 4  \n",
    "\n",
    "becomes\n",
    "\n",
    "1 1 2 2\n",
    "1 1 2 2\n",
    "3 3 4 4 \n",
    "3 3 4 4\n",
    "\n",
    "\n",
    "However, in the upsampling done with respect to Conv2DTranpose, the value of the cell is retained only in the top \n",
    "left cell of the expanded cell block. The remaining cells are set as 0.\n",
    "\n",
    "1 2\n",
    "3 4  \n",
    "\n",
    "becomes\n",
    "\n",
    "1 0 2 0\n",
    "0 0 0 0\n",
    "3 0 4 0 \n",
    "0 0 0 0\n",
    "\n",
    "So we do this upsammpling of the matrix x manually and store it in the variable y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([[1,0,0,0,0,0],\n",
    "             [0,0,0,0,0,0],\n",
    "             [0,0,1,0,0,0],\n",
    "             [0,0,0,0,0,0],\n",
    "             [0,0,0,0,1,0],\n",
    "             [0,0,0,0,0,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.265,  0.31 ,  0.   ,  0.   ,  0.   ,  0.   ],\n",
       "       [-0.549,  0.069,  0.341, -0.321,  0.   ,  0.   ],\n",
       "       [ 0.   , -0.367, -0.265,  0.31 ,  0.   ,  0.   ],\n",
       "       [ 0.   ,  0.261, -0.549,  0.069,  0.341, -0.321],\n",
       "       [ 0.   ,  0.   ,  0.   , -0.367, -0.265,  0.31 ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.261, -0.549,  0.491]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.matrix.round(convolve(y,np.flip(np.flip(getKernel(weight, kernel=0),0),1),padding=(1,1)),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.265,  0.31 ,  0.   ,  0.   ,  0.   ,  0.   ],\n",
       "       [-0.549,  0.069,  0.341, -0.321,  0.   ,  0.   ],\n",
       "       [ 0.   , -0.367, -0.265,  0.31 ,  0.   ,  0.   ],\n",
       "       [ 0.   ,  0.261, -0.549,  0.069,  0.341, -0.321],\n",
       "       [ 0.   ,  0.   ,  0.   , -0.367, -0.265,  0.31 ],\n",
       "       [ 0.   ,  0.   ,  0.   ,  0.261, -0.549,  0.491]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.matrix.round(deconvolve(x_final,getKernel(weight, kernel=0),stride=2),3)[1:7,1:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
